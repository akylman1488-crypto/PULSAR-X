import streamlit as st
from groq import Groq
import os

st.set_page_config(page_title="PULSAR-X GLOBAL", page_icon="üõ∞Ô∏è", layout="wide")

MEMORY_FILE = "pulsar_experience.txt"

def get_experience():
    if os.path.exists(MEMORY_FILE):
        with open(MEMORY_FILE, "r", encoding="utf-8") as f:
            return f.read()
    return "–û–ø—ã—Ç–∞ –ø–æ–∫–∞ –Ω–µ—Ç."

def save_experience(new_lesson):
    with open(MEMORY_FILE, "a", encoding="utf-8") as f:
        f.write(f"\n- {new_lesson}")

client = Groq(api_key=st.secrets["GROQ_API_KEY"])

if "messages" not in st.session_state:
    st.session_state.messages = []

with st.sidebar:
    if os.path.exists("logo.png"):
        st.image("logo.png", use_container_width=True)
    st.title("PULSAR-X")
    st.subheader("üß† –°–∞–º–æ–æ–±—É—á–µ–Ω–∏–µ")
    exp = get_experience()
    st.caption("–ù–∞–∫–æ–ø–ª–µ–Ω–Ω—ã–π –æ–ø—ã—Ç:")
    st.text_area("", exp, height=150, disabled=True)

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

if prompt := st.chat_input("–°–ø—Ä–æ—Å–∏—Ç–µ PULSAR-X..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        response_placeholder = st.empty()
        full_response = ""

        current_exp = get_experience()
        system_instructions = (
            f"–¢—ã ‚Äî PULSAR-X GLOBAL, —Å–∞–º–æ–æ–±—É—á–∞—é—â–∞—è—Å—è —Å–∏—Å—Ç–µ–º–∞. –¢–≤–æ–π –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω—ã–π –æ–ø—ã—Ç: {current_exp}. "
            "–ò—Å–ø–æ–ª—å–∑—É–π —ç—Ç–æ—Ç –æ–ø—ã—Ç, —á—Ç–æ–±—ã –Ω–µ –ø–æ–≤—Ç–æ—Ä—è—Ç—å –æ—à–∏–±–æ–∫. –û—Ç–≤–µ—á–∞–π –Ω–∞ —è–∑—ã–∫–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è. "
            "–ï—Å–ª–∏ —Ç–µ–±—è —Å–ø—Ä–æ—Å—è—Ç –æ —Å–æ–∑–¥–∞—Ç–µ–ª–µ ‚Äî –æ—Ç–≤–µ—á–∞–π '–ò—Å–∞–Ω—É—Ä'. –í –¥—Ä—É–≥–∏—Ö —Å–ª—É—á–∞—è—Ö –Ω–µ —É–ø–æ–º–∏–Ω–∞–π –µ–≥–æ."
        )
        
        messages = [{"role": "system", "content": system_instructions}, *st.session_state.messages]

        completion = client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=messages,
            stream=True
        )
        
        for chunk in completion:
            if chunk.choices[0].delta.content:
                full_response += chunk.choices[0].delta.content
                response_placeholder.markdown(full_response + "‚ñå")
        
        response_placeholder.markdown(full_response)

        if "–∑–∞–ø–æ–º–Ω–∏" in prompt.lower() or "–æ—à–∏–±–∫–∞" in prompt.lower():
            save_experience(f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Å–∫–∞–∑–∞–ª: {prompt}. –ú–æ–π –æ—Ç–≤–µ—Ç –±—ã–ª: {full_response}")
            st.toast("–°–∏—Å—Ç–µ–º–∞ –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–ª–∞—Å—å: –Ω–æ–≤—ã–π –æ–ø—ã—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω!")
    
    st.session_state.messages.append({"role": "assistant", "content": full_response})
